// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.5
//   protoc               v3.21.12
// source: pipeline_core_types.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Struct, Value } from "./google/protobuf/struct";
import { Timestamp } from "./google/protobuf/timestamp";

export const protobufPackage = "io.pipeline.search.model";

export enum ActionType {
  CREATE = 0,
  UPDATE = 1,
  DELETE = 2,
  NO_OP = 3,
  UNRECOGNIZED = -1,
}

export function actionTypeFromJSON(object: any): ActionType {
  switch (object) {
    case 0:
    case "CREATE":
      return ActionType.CREATE;
    case 1:
    case "UPDATE":
      return ActionType.UPDATE;
    case 2:
    case "DELETE":
      return ActionType.DELETE;
    case 3:
    case "NO_OP":
      return ActionType.NO_OP;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ActionType.UNRECOGNIZED;
  }
}

export function actionTypeToJSON(object: ActionType): string {
  switch (object) {
    case ActionType.CREATE:
      return "CREATE";
    case ActionType.UPDATE:
      return "UPDATE";
    case ActionType.DELETE:
      return "DELETE";
    case ActionType.NO_OP:
      return "NO_OP";
    case ActionType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Information about a batch operation */
export interface BatchInfo {
  /** Unique identifier for this batch */
  batchId: string;
  /** Total number of items in the batch */
  totalItems: number;
  /** This item's position in the batch (1-based) */
  currentItemNumber: number;
  /** Human-readable name/description of the batch */
  batchName: string;
  /** When this batch started processing */
  startedAt:
    | Date
    | undefined;
  /** Source of the batch (e.g., "pg_catalog.csv", "wikipedia-20240101.json") */
  sourceReference?: string | undefined;
}

/** Represents a single named vector embedding, typically for a whole document or a non-chunk segment. */
export interface Embedding {
  /** Optional: Name or identifier for the model that generated this embedding. */
  modelId?:
    | string
    | undefined;
  /** The vector representation. */
  vector: number[];
}

/** Represents the text content and vector embedding for a single chunk. */
export interface ChunkEmbedding {
  /** The actual text content of the chunk. */
  textContent: string;
  /** The vector embedding for this chunk's text. */
  vector: number[];
  /** Unique identifier for this chunk. */
  chunkId?:
    | string
    | undefined;
  /** Optional: start offset in original document. */
  originalCharStartOffset?:
    | number
    | undefined;
  /** Optional: end offset in original document. */
  originalCharEndOffset?:
    | number
    | undefined;
  /** Optional: Identifier for a group of related chunks. */
  chunkGroupId?:
    | string
    | undefined;
  /** Optional: Identifier for the chunking configuration used. */
  chunkConfigId?: string | undefined;
}

/** Represents a single semantic chunk of text with its embedding. */
export interface SemanticChunk {
  /** Unique identifier for this specific chunk within its parent SemanticProcessingResult. */
  chunkId: string;
  /** Sequential number of the chunk within its parent SemanticProcessingResult. */
  chunkNumber: number;
  /** The text and embedding for this chunk. */
  embeddingInfo:
    | ChunkEmbedding
    | undefined;
  /** Optional metadata specific to this chunk (e.g., original page number, section). */
  metadata: { [key: string]: any | undefined };
}

export interface SemanticChunk_MetadataEntry {
  key: string;
  value: any | undefined;
}

/**
 * Represents the complete result of one specific semantic chunking and/or embedding process
 * applied to a field of a PipeDoc. A PipeDoc can store multiple such results.
 */
export interface SemanticProcessingResult {
  /** Unique ID for this specific result set (e.g., UUID for this instance of processing). */
  resultId: string;
  /** Name of the field within the parent PipeDoc that was processed (e.g., "body", "title"). */
  sourceFieldName: string;
  /** Identifier for the chunking configuration used (e.g., "sentence_splitter_v1", "token_chunker_512_overlap_50"). */
  chunkConfigId: string;
  /** Identifier for the embedding model/configuration used (e.g., "ada_002_v1", "minilm_l6_v2"). */
  embeddingConfigId: string;
  /**
   * A generated identifier/name for this set of (chunked and) embedded data.
   * Useful as a prefix for field names in a search index or for display/selection.
   * Example: "body_chunks_ada_002", "title_sentences_minilm"
   * This would typically be generated by the pipeline step that produces this result.
   */
  resultSetName?:
    | string
    | undefined;
  /** List of semantic chunks with their embeddings produced by this specific configuration. */
  chunks: SemanticChunk[];
  /** Metadata about this specific processing run (e.g., model version details, execution time). */
  metadata: { [key: string]: any | undefined };
}

export interface SemanticProcessingResult_MetadataEntry {
  key: string;
  value: any | undefined;
}

export interface PipeDoc {
  /** REQUIRED. Unique identifier for the document. */
  id: string;
  /** Optional. URI where the original document came from (e.g., s3://, http://). */
  sourceUri?:
    | string
    | undefined;
  /** Optional. Original MIME type of the content that *led* to this PipeDoc (e.g., "application/pdf"). */
  sourceMimeType?: string | undefined;
  title?:
    | string
    | undefined;
  /** Main textual content, often the target for chunking/embedding. */
  body?: string | undefined;
  keywords: string[];
  /** e.g., "article", "product", "email". */
  documentType?:
    | string
    | undefined;
  /** Optional. Version identifier for the source content. */
  revisionId?:
    | string
    | undefined;
  /** When the source document was created or first seen. */
  creationDate?:
    | Date
    | undefined;
  /** When the source document content was last modified. */
  lastModifiedDate?:
    | Date
    | undefined;
  /** When this PipeDoc representation was last significantly processed/updated by the pipeline. */
  processedDate?:
    | Date
    | undefined;
  /** For flexible, non-standard structured data related to the document. */
  customData?:
    | { [key: string]: any }
    | undefined;
  /** Holds results from potentially multiple, different chunking and/or embedding processes applied to this document. */
  semanticResults: SemanticProcessingResult[];
  /**
   * Map for storing other named embeddings (e.g., whole document embeddings, image embeddings).
   * Key could be a descriptive name like "full_document_ada_002_embedding" or "header_image_clip_embedding".
   */
  namedEmbeddings: { [key: string]: Embedding };
  /** binary data and associated metadata */
  blob?:
    | Blob
    | undefined;
  /** optional metadata */
  metadata: { [key: string]: string };
}

export interface PipeDoc_NamedEmbeddingsEntry {
  key: string;
  value: Embedding | undefined;
}

export interface PipeDoc_MetadataEntry {
  key: string;
  value: string;
}

export interface Blob {
  /** Optional: Unique identifier for this blob (e.g., hash of content or UUID). */
  blobId?:
    | string
    | undefined;
  /** REQUIRED. The raw binary content. */
  data: Uint8Array;
  /** MIME type of the content in 'data' (e.g., "application/pdf", "image/jpeg"). */
  mimeType?:
    | string
    | undefined;
  /** Optional: Original filename associated with this binary data. */
  filename?:
    | string
    | undefined;
  /** Optional: Character encoding if 'data' represents text (e.g., "UTF-8"). */
  encoding?:
    | string
    | undefined;
  /** Optional: Additional key-value metadata specific to this blob. */
  metadata: { [key: string]: string };
}

export interface Blob_MetadataEntry {
  key: string;
  value: string;
}

/** Captures input state for a failed step attempt, used within ErrorData. */
export interface FailedStepInputState {
  /** The PipeDoc as it was *before* the failed step was attempted. */
  docState?:
    | PipeDoc
    | undefined;
  /** The Blob as it was *before* the failed step was attempted. */
  blobState?:
    | Blob
    | undefined;
  /** The custom_json_config (as Struct) provided to the failed step. */
  customConfigStruct?:
    | { [key: string]: any }
    | undefined;
  /** The config_params provided to the failed step. */
  configParams: { [key: string]: string };
}

export interface FailedStepInputState_ConfigParamsEntry {
  key: string;
  value: string;
}

export interface ErrorData {
  /** REQUIRED. Human-readable description of the error. */
  errorMessage: string;
  /** Optional. Machine-readable error code (e.g., "CONFIG_VALIDATION_ERROR", "TIMEOUT_ERROR"). */
  errorCode?:
    | string
    | undefined;
  /** Optional. Snippet of stack trace, detailed diagnostic information. */
  technicalDetails?:
    | string
    | undefined;
  /** REQUIRED. The 'stepName' of the PipelineStepConfig where the error originated or was detected. */
  originatingStepName: string;
  /** Optional. If error occurred during an attempt to route or dispatch to a *next* step. */
  attemptedTargetStepName?:
    | string
    | undefined;
  /** Optional. State of data/config when the step failed, for reproducibility. */
  inputStateAtFailure?:
    | FailedStepInputState
    | undefined;
  /** REQUIRED. When the error occurred or was logged. */
  timestamp: Date | undefined;
}

export interface StepExecutionRecord {
  /** Sequential hop number for this step in the stream. */
  hopNumber: number;
  /** 'stepName' of the PipelineStepConfig that was executed. */
  stepName: string;
  /** Optional. Identifier of the specific service instance/pod that executed the step. */
  serviceInstanceId?:
    | string
    | undefined;
  /** When step processing began. */
  startTime:
    | Date
    | undefined;
  /** When step processing ended. */
  endTime:
    | Date
    | undefined;
  /** Expected statuses: "SUCCESS", "FAILURE", "SKIPPED" (add more as needed, e.g., "RETRYING") */
  status: string;
  /** Logs specifically from the processor for this step's execution. */
  processorLogs: string[];
  /** Specific error from *this step* if status is "FAILURE". */
  errorInfo?:
    | ErrorData
    | undefined;
  /** Optional. If status is "DISPATCH_FAILURE", this is the */
  attemptedTargetStepName?: string | undefined;
}

export interface PipeStream {
  /** REQUIRED. Unique ID for this execution flow instance. */
  streamId: string;
  /** REQUIRED (can be an empty message initially). The primary document being processed. */
  document:
    | PipeDoc
    | undefined;
  /** REQUIRED. Name of the PipelineConfig being executed. */
  currentPipelineName: string;
  /**
   * REQUIRED by the sender (Engine or Kafka Framework).
   * The 'stepName' (key from PipelineConfig.steps map) of the PipelineStepConfig
   * that is the intended next recipient/processor of this PipeStream.
   */
  targetStepName: string;
  /** For logging/tracing; incremented by the engine/framework *before* dispatching to */
  currentHopNumber: number;
  /** target_step_name. */
  history: StepExecutionRecord[];
  /** Holds the first critical error that puts the *entire stream* into a general error */
  streamErrorData?:
    | ErrorData
    | undefined;
  /** state, possibly halting further processing unless handled by an error pipeline. */
  contextParams: { [key: string]: string };
  /** correlation_id). */
  actionType: ActionType;
}

export interface PipeStream_ContextParamsEntry {
  key: string;
  value: string;
}

function createBaseBatchInfo(): BatchInfo {
  return {
    batchId: "",
    totalItems: 0,
    currentItemNumber: 0,
    batchName: "",
    startedAt: undefined,
    sourceReference: undefined,
  };
}

export const BatchInfo: MessageFns<BatchInfo> = {
  encode(message: BatchInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.batchId !== "") {
      writer.uint32(10).string(message.batchId);
    }
    if (message.totalItems !== 0) {
      writer.uint32(16).int64(message.totalItems);
    }
    if (message.currentItemNumber !== 0) {
      writer.uint32(24).int64(message.currentItemNumber);
    }
    if (message.batchName !== "") {
      writer.uint32(34).string(message.batchName);
    }
    if (message.startedAt !== undefined) {
      Timestamp.encode(toTimestamp(message.startedAt), writer.uint32(42).fork()).join();
    }
    if (message.sourceReference !== undefined) {
      writer.uint32(50).string(message.sourceReference);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BatchInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.batchId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.totalItems = longToNumber(reader.int64());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.currentItemNumber = longToNumber(reader.int64());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.batchName = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.startedAt = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.sourceReference = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchInfo {
    return {
      batchId: isSet(object.batchId) ? globalThis.String(object.batchId) : "",
      totalItems: isSet(object.totalItems) ? globalThis.Number(object.totalItems) : 0,
      currentItemNumber: isSet(object.currentItemNumber) ? globalThis.Number(object.currentItemNumber) : 0,
      batchName: isSet(object.batchName) ? globalThis.String(object.batchName) : "",
      startedAt: isSet(object.startedAt) ? fromJsonTimestamp(object.startedAt) : undefined,
      sourceReference: isSet(object.sourceReference) ? globalThis.String(object.sourceReference) : undefined,
    };
  },

  toJSON(message: BatchInfo): unknown {
    const obj: any = {};
    if (message.batchId !== "") {
      obj.batchId = message.batchId;
    }
    if (message.totalItems !== 0) {
      obj.totalItems = Math.round(message.totalItems);
    }
    if (message.currentItemNumber !== 0) {
      obj.currentItemNumber = Math.round(message.currentItemNumber);
    }
    if (message.batchName !== "") {
      obj.batchName = message.batchName;
    }
    if (message.startedAt !== undefined) {
      obj.startedAt = message.startedAt.toISOString();
    }
    if (message.sourceReference !== undefined) {
      obj.sourceReference = message.sourceReference;
    }
    return obj;
  },
};

function createBaseEmbedding(): Embedding {
  return { modelId: undefined, vector: [] };
}

export const Embedding: MessageFns<Embedding> = {
  encode(message: Embedding, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.modelId !== undefined) {
      writer.uint32(10).string(message.modelId);
    }
    writer.uint32(18).fork();
    for (const v of message.vector) {
      writer.float(v);
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Embedding {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEmbedding();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.modelId = reader.string();
          continue;
        }
        case 2: {
          if (tag === 21) {
            message.vector.push(reader.float());

            continue;
          }

          if (tag === 18) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.vector.push(reader.float());
            }

            continue;
          }

          break;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Embedding {
    return {
      modelId: isSet(object.modelId) ? globalThis.String(object.modelId) : undefined,
      vector: globalThis.Array.isArray(object?.vector) ? object.vector.map((e: any) => globalThis.Number(e)) : [],
    };
  },

  toJSON(message: Embedding): unknown {
    const obj: any = {};
    if (message.modelId !== undefined) {
      obj.modelId = message.modelId;
    }
    if (message.vector?.length) {
      obj.vector = message.vector;
    }
    return obj;
  },
};

function createBaseChunkEmbedding(): ChunkEmbedding {
  return {
    textContent: "",
    vector: [],
    chunkId: undefined,
    originalCharStartOffset: undefined,
    originalCharEndOffset: undefined,
    chunkGroupId: undefined,
    chunkConfigId: undefined,
  };
}

export const ChunkEmbedding: MessageFns<ChunkEmbedding> = {
  encode(message: ChunkEmbedding, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.textContent !== "") {
      writer.uint32(10).string(message.textContent);
    }
    writer.uint32(18).fork();
    for (const v of message.vector) {
      writer.float(v);
    }
    writer.join();
    if (message.chunkId !== undefined) {
      writer.uint32(26).string(message.chunkId);
    }
    if (message.originalCharStartOffset !== undefined) {
      writer.uint32(32).int32(message.originalCharStartOffset);
    }
    if (message.originalCharEndOffset !== undefined) {
      writer.uint32(40).int32(message.originalCharEndOffset);
    }
    if (message.chunkGroupId !== undefined) {
      writer.uint32(50).string(message.chunkGroupId);
    }
    if (message.chunkConfigId !== undefined) {
      writer.uint32(58).string(message.chunkConfigId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ChunkEmbedding {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseChunkEmbedding();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.textContent = reader.string();
          continue;
        }
        case 2: {
          if (tag === 21) {
            message.vector.push(reader.float());

            continue;
          }

          if (tag === 18) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.vector.push(reader.float());
            }

            continue;
          }

          break;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.chunkId = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.originalCharStartOffset = reader.int32();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.originalCharEndOffset = reader.int32();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.chunkGroupId = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.chunkConfigId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ChunkEmbedding {
    return {
      textContent: isSet(object.textContent) ? globalThis.String(object.textContent) : "",
      vector: globalThis.Array.isArray(object?.vector) ? object.vector.map((e: any) => globalThis.Number(e)) : [],
      chunkId: isSet(object.chunkId) ? globalThis.String(object.chunkId) : undefined,
      originalCharStartOffset: isSet(object.originalCharStartOffset)
        ? globalThis.Number(object.originalCharStartOffset)
        : undefined,
      originalCharEndOffset: isSet(object.originalCharEndOffset)
        ? globalThis.Number(object.originalCharEndOffset)
        : undefined,
      chunkGroupId: isSet(object.chunkGroupId) ? globalThis.String(object.chunkGroupId) : undefined,
      chunkConfigId: isSet(object.chunkConfigId) ? globalThis.String(object.chunkConfigId) : undefined,
    };
  },

  toJSON(message: ChunkEmbedding): unknown {
    const obj: any = {};
    if (message.textContent !== "") {
      obj.textContent = message.textContent;
    }
    if (message.vector?.length) {
      obj.vector = message.vector;
    }
    if (message.chunkId !== undefined) {
      obj.chunkId = message.chunkId;
    }
    if (message.originalCharStartOffset !== undefined) {
      obj.originalCharStartOffset = Math.round(message.originalCharStartOffset);
    }
    if (message.originalCharEndOffset !== undefined) {
      obj.originalCharEndOffset = Math.round(message.originalCharEndOffset);
    }
    if (message.chunkGroupId !== undefined) {
      obj.chunkGroupId = message.chunkGroupId;
    }
    if (message.chunkConfigId !== undefined) {
      obj.chunkConfigId = message.chunkConfigId;
    }
    return obj;
  },
};

function createBaseSemanticChunk(): SemanticChunk {
  return { chunkId: "", chunkNumber: 0, embeddingInfo: undefined, metadata: {} };
}

export const SemanticChunk: MessageFns<SemanticChunk> = {
  encode(message: SemanticChunk, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.chunkId !== "") {
      writer.uint32(10).string(message.chunkId);
    }
    if (message.chunkNumber !== 0) {
      writer.uint32(16).int64(message.chunkNumber);
    }
    if (message.embeddingInfo !== undefined) {
      ChunkEmbedding.encode(message.embeddingInfo, writer.uint32(26).fork()).join();
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      if (value !== undefined) {
        SemanticChunk_MetadataEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
      }
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SemanticChunk {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSemanticChunk();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.chunkId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.chunkNumber = longToNumber(reader.int64());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.embeddingInfo = ChunkEmbedding.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = SemanticChunk_MetadataEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.metadata[entry4.key] = entry4.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SemanticChunk {
    return {
      chunkId: isSet(object.chunkId) ? globalThis.String(object.chunkId) : "",
      chunkNumber: isSet(object.chunkNumber) ? globalThis.Number(object.chunkNumber) : 0,
      embeddingInfo: isSet(object.embeddingInfo) ? ChunkEmbedding.fromJSON(object.embeddingInfo) : undefined,
      metadata: isObject(object.metadata)
        ? Object.entries(object.metadata).reduce<{ [key: string]: any | undefined }>((acc, [key, value]) => {
          acc[key] = value as any | undefined;
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: SemanticChunk): unknown {
    const obj: any = {};
    if (message.chunkId !== "") {
      obj.chunkId = message.chunkId;
    }
    if (message.chunkNumber !== 0) {
      obj.chunkNumber = Math.round(message.chunkNumber);
    }
    if (message.embeddingInfo !== undefined) {
      obj.embeddingInfo = ChunkEmbedding.toJSON(message.embeddingInfo);
    }
    if (message.metadata) {
      const entries = Object.entries(message.metadata);
      if (entries.length > 0) {
        obj.metadata = {};
        entries.forEach(([k, v]) => {
          obj.metadata[k] = v;
        });
      }
    }
    return obj;
  },
};

function createBaseSemanticChunk_MetadataEntry(): SemanticChunk_MetadataEntry {
  return { key: "", value: undefined };
}

export const SemanticChunk_MetadataEntry: MessageFns<SemanticChunk_MetadataEntry> = {
  encode(message: SemanticChunk_MetadataEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      Value.encode(Value.wrap(message.value), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SemanticChunk_MetadataEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSemanticChunk_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = Value.unwrap(Value.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SemanticChunk_MetadataEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object?.value) ? object.value : undefined,
    };
  },

  toJSON(message: SemanticChunk_MetadataEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = message.value;
    }
    return obj;
  },
};

function createBaseSemanticProcessingResult(): SemanticProcessingResult {
  return {
    resultId: "",
    sourceFieldName: "",
    chunkConfigId: "",
    embeddingConfigId: "",
    resultSetName: undefined,
    chunks: [],
    metadata: {},
  };
}

export const SemanticProcessingResult: MessageFns<SemanticProcessingResult> = {
  encode(message: SemanticProcessingResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resultId !== "") {
      writer.uint32(10).string(message.resultId);
    }
    if (message.sourceFieldName !== "") {
      writer.uint32(18).string(message.sourceFieldName);
    }
    if (message.chunkConfigId !== "") {
      writer.uint32(26).string(message.chunkConfigId);
    }
    if (message.embeddingConfigId !== "") {
      writer.uint32(34).string(message.embeddingConfigId);
    }
    if (message.resultSetName !== undefined) {
      writer.uint32(42).string(message.resultSetName);
    }
    for (const v of message.chunks) {
      SemanticChunk.encode(v!, writer.uint32(50).fork()).join();
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      if (value !== undefined) {
        SemanticProcessingResult_MetadataEntry.encode({ key: key as any, value }, writer.uint32(58).fork()).join();
      }
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SemanticProcessingResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSemanticProcessingResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.resultId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.sourceFieldName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.chunkConfigId = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.embeddingConfigId = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.resultSetName = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.chunks.push(SemanticChunk.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          const entry7 = SemanticProcessingResult_MetadataEntry.decode(reader, reader.uint32());
          if (entry7.value !== undefined) {
            message.metadata[entry7.key] = entry7.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SemanticProcessingResult {
    return {
      resultId: isSet(object.resultId) ? globalThis.String(object.resultId) : "",
      sourceFieldName: isSet(object.sourceFieldName) ? globalThis.String(object.sourceFieldName) : "",
      chunkConfigId: isSet(object.chunkConfigId) ? globalThis.String(object.chunkConfigId) : "",
      embeddingConfigId: isSet(object.embeddingConfigId) ? globalThis.String(object.embeddingConfigId) : "",
      resultSetName: isSet(object.resultSetName) ? globalThis.String(object.resultSetName) : undefined,
      chunks: globalThis.Array.isArray(object?.chunks) ? object.chunks.map((e: any) => SemanticChunk.fromJSON(e)) : [],
      metadata: isObject(object.metadata)
        ? Object.entries(object.metadata).reduce<{ [key: string]: any | undefined }>((acc, [key, value]) => {
          acc[key] = value as any | undefined;
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: SemanticProcessingResult): unknown {
    const obj: any = {};
    if (message.resultId !== "") {
      obj.resultId = message.resultId;
    }
    if (message.sourceFieldName !== "") {
      obj.sourceFieldName = message.sourceFieldName;
    }
    if (message.chunkConfigId !== "") {
      obj.chunkConfigId = message.chunkConfigId;
    }
    if (message.embeddingConfigId !== "") {
      obj.embeddingConfigId = message.embeddingConfigId;
    }
    if (message.resultSetName !== undefined) {
      obj.resultSetName = message.resultSetName;
    }
    if (message.chunks?.length) {
      obj.chunks = message.chunks.map((e) => SemanticChunk.toJSON(e));
    }
    if (message.metadata) {
      const entries = Object.entries(message.metadata);
      if (entries.length > 0) {
        obj.metadata = {};
        entries.forEach(([k, v]) => {
          obj.metadata[k] = v;
        });
      }
    }
    return obj;
  },
};

function createBaseSemanticProcessingResult_MetadataEntry(): SemanticProcessingResult_MetadataEntry {
  return { key: "", value: undefined };
}

export const SemanticProcessingResult_MetadataEntry: MessageFns<SemanticProcessingResult_MetadataEntry> = {
  encode(message: SemanticProcessingResult_MetadataEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      Value.encode(Value.wrap(message.value), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SemanticProcessingResult_MetadataEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSemanticProcessingResult_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = Value.unwrap(Value.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SemanticProcessingResult_MetadataEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object?.value) ? object.value : undefined,
    };
  },

  toJSON(message: SemanticProcessingResult_MetadataEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = message.value;
    }
    return obj;
  },
};

function createBasePipeDoc(): PipeDoc {
  return {
    id: "",
    sourceUri: undefined,
    sourceMimeType: undefined,
    title: undefined,
    body: undefined,
    keywords: [],
    documentType: undefined,
    revisionId: undefined,
    creationDate: undefined,
    lastModifiedDate: undefined,
    processedDate: undefined,
    customData: undefined,
    semanticResults: [],
    namedEmbeddings: {},
    blob: undefined,
    metadata: {},
  };
}

export const PipeDoc: MessageFns<PipeDoc> = {
  encode(message: PipeDoc, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.sourceUri !== undefined) {
      writer.uint32(18).string(message.sourceUri);
    }
    if (message.sourceMimeType !== undefined) {
      writer.uint32(26).string(message.sourceMimeType);
    }
    if (message.title !== undefined) {
      writer.uint32(34).string(message.title);
    }
    if (message.body !== undefined) {
      writer.uint32(42).string(message.body);
    }
    for (const v of message.keywords) {
      writer.uint32(50).string(v!);
    }
    if (message.documentType !== undefined) {
      writer.uint32(58).string(message.documentType);
    }
    if (message.revisionId !== undefined) {
      writer.uint32(66).string(message.revisionId);
    }
    if (message.creationDate !== undefined) {
      Timestamp.encode(toTimestamp(message.creationDate), writer.uint32(74).fork()).join();
    }
    if (message.lastModifiedDate !== undefined) {
      Timestamp.encode(toTimestamp(message.lastModifiedDate), writer.uint32(82).fork()).join();
    }
    if (message.processedDate !== undefined) {
      Timestamp.encode(toTimestamp(message.processedDate), writer.uint32(90).fork()).join();
    }
    if (message.customData !== undefined) {
      Struct.encode(Struct.wrap(message.customData), writer.uint32(98).fork()).join();
    }
    for (const v of message.semanticResults) {
      SemanticProcessingResult.encode(v!, writer.uint32(106).fork()).join();
    }
    Object.entries(message.namedEmbeddings).forEach(([key, value]) => {
      PipeDoc_NamedEmbeddingsEntry.encode({ key: key as any, value }, writer.uint32(114).fork()).join();
    });
    if (message.blob !== undefined) {
      Blob.encode(message.blob, writer.uint32(122).fork()).join();
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      PipeDoc_MetadataEntry.encode({ key: key as any, value }, writer.uint32(130).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PipeDoc {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipeDoc();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.sourceUri = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.sourceMimeType = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.title = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.body = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.keywords.push(reader.string());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.documentType = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.revisionId = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.creationDate = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.lastModifiedDate = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.processedDate = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.customData = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
        }
        case 13: {
          if (tag !== 106) {
            break;
          }

          message.semanticResults.push(SemanticProcessingResult.decode(reader, reader.uint32()));
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          const entry14 = PipeDoc_NamedEmbeddingsEntry.decode(reader, reader.uint32());
          if (entry14.value !== undefined) {
            message.namedEmbeddings[entry14.key] = entry14.value;
          }
          continue;
        }
        case 15: {
          if (tag !== 122) {
            break;
          }

          message.blob = Blob.decode(reader, reader.uint32());
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          const entry16 = PipeDoc_MetadataEntry.decode(reader, reader.uint32());
          if (entry16.value !== undefined) {
            message.metadata[entry16.key] = entry16.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PipeDoc {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      sourceUri: isSet(object.sourceUri) ? globalThis.String(object.sourceUri) : undefined,
      sourceMimeType: isSet(object.sourceMimeType) ? globalThis.String(object.sourceMimeType) : undefined,
      title: isSet(object.title) ? globalThis.String(object.title) : undefined,
      body: isSet(object.body) ? globalThis.String(object.body) : undefined,
      keywords: globalThis.Array.isArray(object?.keywords) ? object.keywords.map((e: any) => globalThis.String(e)) : [],
      documentType: isSet(object.documentType) ? globalThis.String(object.documentType) : undefined,
      revisionId: isSet(object.revisionId) ? globalThis.String(object.revisionId) : undefined,
      creationDate: isSet(object.creationDate) ? fromJsonTimestamp(object.creationDate) : undefined,
      lastModifiedDate: isSet(object.lastModifiedDate) ? fromJsonTimestamp(object.lastModifiedDate) : undefined,
      processedDate: isSet(object.processedDate) ? fromJsonTimestamp(object.processedDate) : undefined,
      customData: isObject(object.customData) ? object.customData : undefined,
      semanticResults: globalThis.Array.isArray(object?.semanticResults)
        ? object.semanticResults.map((e: any) => SemanticProcessingResult.fromJSON(e))
        : [],
      namedEmbeddings: isObject(object.namedEmbeddings)
        ? Object.entries(object.namedEmbeddings).reduce<{ [key: string]: Embedding }>((acc, [key, value]) => {
          acc[key] = Embedding.fromJSON(value);
          return acc;
        }, {})
        : {},
      blob: isSet(object.blob) ? Blob.fromJSON(object.blob) : undefined,
      metadata: isObject(object.metadata)
        ? Object.entries(object.metadata).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: PipeDoc): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.sourceUri !== undefined) {
      obj.sourceUri = message.sourceUri;
    }
    if (message.sourceMimeType !== undefined) {
      obj.sourceMimeType = message.sourceMimeType;
    }
    if (message.title !== undefined) {
      obj.title = message.title;
    }
    if (message.body !== undefined) {
      obj.body = message.body;
    }
    if (message.keywords?.length) {
      obj.keywords = message.keywords;
    }
    if (message.documentType !== undefined) {
      obj.documentType = message.documentType;
    }
    if (message.revisionId !== undefined) {
      obj.revisionId = message.revisionId;
    }
    if (message.creationDate !== undefined) {
      obj.creationDate = message.creationDate.toISOString();
    }
    if (message.lastModifiedDate !== undefined) {
      obj.lastModifiedDate = message.lastModifiedDate.toISOString();
    }
    if (message.processedDate !== undefined) {
      obj.processedDate = message.processedDate.toISOString();
    }
    if (message.customData !== undefined) {
      obj.customData = message.customData;
    }
    if (message.semanticResults?.length) {
      obj.semanticResults = message.semanticResults.map((e) => SemanticProcessingResult.toJSON(e));
    }
    if (message.namedEmbeddings) {
      const entries = Object.entries(message.namedEmbeddings);
      if (entries.length > 0) {
        obj.namedEmbeddings = {};
        entries.forEach(([k, v]) => {
          obj.namedEmbeddings[k] = Embedding.toJSON(v);
        });
      }
    }
    if (message.blob !== undefined) {
      obj.blob = Blob.toJSON(message.blob);
    }
    if (message.metadata) {
      const entries = Object.entries(message.metadata);
      if (entries.length > 0) {
        obj.metadata = {};
        entries.forEach(([k, v]) => {
          obj.metadata[k] = v;
        });
      }
    }
    return obj;
  },
};

function createBasePipeDoc_NamedEmbeddingsEntry(): PipeDoc_NamedEmbeddingsEntry {
  return { key: "", value: undefined };
}

export const PipeDoc_NamedEmbeddingsEntry: MessageFns<PipeDoc_NamedEmbeddingsEntry> = {
  encode(message: PipeDoc_NamedEmbeddingsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      Embedding.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PipeDoc_NamedEmbeddingsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipeDoc_NamedEmbeddingsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = Embedding.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PipeDoc_NamedEmbeddingsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? Embedding.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: PipeDoc_NamedEmbeddingsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = Embedding.toJSON(message.value);
    }
    return obj;
  },
};

function createBasePipeDoc_MetadataEntry(): PipeDoc_MetadataEntry {
  return { key: "", value: "" };
}

export const PipeDoc_MetadataEntry: MessageFns<PipeDoc_MetadataEntry> = {
  encode(message: PipeDoc_MetadataEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PipeDoc_MetadataEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipeDoc_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PipeDoc_MetadataEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: PipeDoc_MetadataEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },
};

function createBaseBlob(): Blob {
  return {
    blobId: undefined,
    data: new Uint8Array(0),
    mimeType: undefined,
    filename: undefined,
    encoding: undefined,
    metadata: {},
  };
}

export const Blob: MessageFns<Blob> = {
  encode(message: Blob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.blobId !== undefined) {
      writer.uint32(10).string(message.blobId);
    }
    if (message.data.length !== 0) {
      writer.uint32(18).bytes(message.data);
    }
    if (message.mimeType !== undefined) {
      writer.uint32(26).string(message.mimeType);
    }
    if (message.filename !== undefined) {
      writer.uint32(34).string(message.filename);
    }
    if (message.encoding !== undefined) {
      writer.uint32(42).string(message.encoding);
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      Blob_MetadataEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Blob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBlob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.blobId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.data = reader.bytes();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.mimeType = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.filename = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.encoding = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          const entry6 = Blob_MetadataEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.metadata[entry6.key] = entry6.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Blob {
    return {
      blobId: isSet(object.blobId) ? globalThis.String(object.blobId) : undefined,
      data: isSet(object.data) ? bytesFromBase64(object.data) : new Uint8Array(0),
      mimeType: isSet(object.mimeType) ? globalThis.String(object.mimeType) : undefined,
      filename: isSet(object.filename) ? globalThis.String(object.filename) : undefined,
      encoding: isSet(object.encoding) ? globalThis.String(object.encoding) : undefined,
      metadata: isObject(object.metadata)
        ? Object.entries(object.metadata).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: Blob): unknown {
    const obj: any = {};
    if (message.blobId !== undefined) {
      obj.blobId = message.blobId;
    }
    if (message.data.length !== 0) {
      obj.data = base64FromBytes(message.data);
    }
    if (message.mimeType !== undefined) {
      obj.mimeType = message.mimeType;
    }
    if (message.filename !== undefined) {
      obj.filename = message.filename;
    }
    if (message.encoding !== undefined) {
      obj.encoding = message.encoding;
    }
    if (message.metadata) {
      const entries = Object.entries(message.metadata);
      if (entries.length > 0) {
        obj.metadata = {};
        entries.forEach(([k, v]) => {
          obj.metadata[k] = v;
        });
      }
    }
    return obj;
  },
};

function createBaseBlob_MetadataEntry(): Blob_MetadataEntry {
  return { key: "", value: "" };
}

export const Blob_MetadataEntry: MessageFns<Blob_MetadataEntry> = {
  encode(message: Blob_MetadataEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Blob_MetadataEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBlob_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Blob_MetadataEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Blob_MetadataEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },
};

function createBaseFailedStepInputState(): FailedStepInputState {
  return { docState: undefined, blobState: undefined, customConfigStruct: undefined, configParams: {} };
}

export const FailedStepInputState: MessageFns<FailedStepInputState> = {
  encode(message: FailedStepInputState, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.docState !== undefined) {
      PipeDoc.encode(message.docState, writer.uint32(10).fork()).join();
    }
    if (message.blobState !== undefined) {
      Blob.encode(message.blobState, writer.uint32(18).fork()).join();
    }
    if (message.customConfigStruct !== undefined) {
      Struct.encode(Struct.wrap(message.customConfigStruct), writer.uint32(26).fork()).join();
    }
    Object.entries(message.configParams).forEach(([key, value]) => {
      FailedStepInputState_ConfigParamsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FailedStepInputState {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFailedStepInputState();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.docState = PipeDoc.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.blobState = Blob.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.customConfigStruct = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = FailedStepInputState_ConfigParamsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.configParams[entry4.key] = entry4.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FailedStepInputState {
    return {
      docState: isSet(object.docState) ? PipeDoc.fromJSON(object.docState) : undefined,
      blobState: isSet(object.blobState) ? Blob.fromJSON(object.blobState) : undefined,
      customConfigStruct: isObject(object.customConfigStruct) ? object.customConfigStruct : undefined,
      configParams: isObject(object.configParams)
        ? Object.entries(object.configParams).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: FailedStepInputState): unknown {
    const obj: any = {};
    if (message.docState !== undefined) {
      obj.docState = PipeDoc.toJSON(message.docState);
    }
    if (message.blobState !== undefined) {
      obj.blobState = Blob.toJSON(message.blobState);
    }
    if (message.customConfigStruct !== undefined) {
      obj.customConfigStruct = message.customConfigStruct;
    }
    if (message.configParams) {
      const entries = Object.entries(message.configParams);
      if (entries.length > 0) {
        obj.configParams = {};
        entries.forEach(([k, v]) => {
          obj.configParams[k] = v;
        });
      }
    }
    return obj;
  },
};

function createBaseFailedStepInputState_ConfigParamsEntry(): FailedStepInputState_ConfigParamsEntry {
  return { key: "", value: "" };
}

export const FailedStepInputState_ConfigParamsEntry: MessageFns<FailedStepInputState_ConfigParamsEntry> = {
  encode(message: FailedStepInputState_ConfigParamsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FailedStepInputState_ConfigParamsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFailedStepInputState_ConfigParamsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FailedStepInputState_ConfigParamsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: FailedStepInputState_ConfigParamsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },
};

function createBaseErrorData(): ErrorData {
  return {
    errorMessage: "",
    errorCode: undefined,
    technicalDetails: undefined,
    originatingStepName: "",
    attemptedTargetStepName: undefined,
    inputStateAtFailure: undefined,
    timestamp: undefined,
  };
}

export const ErrorData: MessageFns<ErrorData> = {
  encode(message: ErrorData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.errorMessage !== "") {
      writer.uint32(10).string(message.errorMessage);
    }
    if (message.errorCode !== undefined) {
      writer.uint32(18).string(message.errorCode);
    }
    if (message.technicalDetails !== undefined) {
      writer.uint32(26).string(message.technicalDetails);
    }
    if (message.originatingStepName !== "") {
      writer.uint32(34).string(message.originatingStepName);
    }
    if (message.attemptedTargetStepName !== undefined) {
      writer.uint32(42).string(message.attemptedTargetStepName);
    }
    if (message.inputStateAtFailure !== undefined) {
      FailedStepInputState.encode(message.inputStateAtFailure, writer.uint32(50).fork()).join();
    }
    if (message.timestamp !== undefined) {
      Timestamp.encode(toTimestamp(message.timestamp), writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ErrorData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseErrorData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.errorMessage = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.errorCode = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.technicalDetails = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.originatingStepName = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.attemptedTargetStepName = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.inputStateAtFailure = FailedStepInputState.decode(reader, reader.uint32());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.timestamp = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ErrorData {
    return {
      errorMessage: isSet(object.errorMessage) ? globalThis.String(object.errorMessage) : "",
      errorCode: isSet(object.errorCode) ? globalThis.String(object.errorCode) : undefined,
      technicalDetails: isSet(object.technicalDetails) ? globalThis.String(object.technicalDetails) : undefined,
      originatingStepName: isSet(object.originatingStepName) ? globalThis.String(object.originatingStepName) : "",
      attemptedTargetStepName: isSet(object.attemptedTargetStepName)
        ? globalThis.String(object.attemptedTargetStepName)
        : undefined,
      inputStateAtFailure: isSet(object.inputStateAtFailure)
        ? FailedStepInputState.fromJSON(object.inputStateAtFailure)
        : undefined,
      timestamp: isSet(object.timestamp) ? fromJsonTimestamp(object.timestamp) : undefined,
    };
  },

  toJSON(message: ErrorData): unknown {
    const obj: any = {};
    if (message.errorMessage !== "") {
      obj.errorMessage = message.errorMessage;
    }
    if (message.errorCode !== undefined) {
      obj.errorCode = message.errorCode;
    }
    if (message.technicalDetails !== undefined) {
      obj.technicalDetails = message.technicalDetails;
    }
    if (message.originatingStepName !== "") {
      obj.originatingStepName = message.originatingStepName;
    }
    if (message.attemptedTargetStepName !== undefined) {
      obj.attemptedTargetStepName = message.attemptedTargetStepName;
    }
    if (message.inputStateAtFailure !== undefined) {
      obj.inputStateAtFailure = FailedStepInputState.toJSON(message.inputStateAtFailure);
    }
    if (message.timestamp !== undefined) {
      obj.timestamp = message.timestamp.toISOString();
    }
    return obj;
  },
};

function createBaseStepExecutionRecord(): StepExecutionRecord {
  return {
    hopNumber: 0,
    stepName: "",
    serviceInstanceId: undefined,
    startTime: undefined,
    endTime: undefined,
    status: "",
    processorLogs: [],
    errorInfo: undefined,
    attemptedTargetStepName: undefined,
  };
}

export const StepExecutionRecord: MessageFns<StepExecutionRecord> = {
  encode(message: StepExecutionRecord, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hopNumber !== 0) {
      writer.uint32(8).int64(message.hopNumber);
    }
    if (message.stepName !== "") {
      writer.uint32(18).string(message.stepName);
    }
    if (message.serviceInstanceId !== undefined) {
      writer.uint32(26).string(message.serviceInstanceId);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(34).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(42).fork()).join();
    }
    if (message.status !== "") {
      writer.uint32(50).string(message.status);
    }
    for (const v of message.processorLogs) {
      writer.uint32(58).string(v!);
    }
    if (message.errorInfo !== undefined) {
      ErrorData.encode(message.errorInfo, writer.uint32(66).fork()).join();
    }
    if (message.attemptedTargetStepName !== undefined) {
      writer.uint32(74).string(message.attemptedTargetStepName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StepExecutionRecord {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStepExecutionRecord();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.hopNumber = longToNumber(reader.int64());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.stepName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.serviceInstanceId = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.status = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.processorLogs.push(reader.string());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.errorInfo = ErrorData.decode(reader, reader.uint32());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.attemptedTargetStepName = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StepExecutionRecord {
    return {
      hopNumber: isSet(object.hopNumber) ? globalThis.Number(object.hopNumber) : 0,
      stepName: isSet(object.stepName) ? globalThis.String(object.stepName) : "",
      serviceInstanceId: isSet(object.serviceInstanceId) ? globalThis.String(object.serviceInstanceId) : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      status: isSet(object.status) ? globalThis.String(object.status) : "",
      processorLogs: globalThis.Array.isArray(object?.processorLogs)
        ? object.processorLogs.map((e: any) => globalThis.String(e))
        : [],
      errorInfo: isSet(object.errorInfo) ? ErrorData.fromJSON(object.errorInfo) : undefined,
      attemptedTargetStepName: isSet(object.attemptedTargetStepName)
        ? globalThis.String(object.attemptedTargetStepName)
        : undefined,
    };
  },

  toJSON(message: StepExecutionRecord): unknown {
    const obj: any = {};
    if (message.hopNumber !== 0) {
      obj.hopNumber = Math.round(message.hopNumber);
    }
    if (message.stepName !== "") {
      obj.stepName = message.stepName;
    }
    if (message.serviceInstanceId !== undefined) {
      obj.serviceInstanceId = message.serviceInstanceId;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.status !== "") {
      obj.status = message.status;
    }
    if (message.processorLogs?.length) {
      obj.processorLogs = message.processorLogs;
    }
    if (message.errorInfo !== undefined) {
      obj.errorInfo = ErrorData.toJSON(message.errorInfo);
    }
    if (message.attemptedTargetStepName !== undefined) {
      obj.attemptedTargetStepName = message.attemptedTargetStepName;
    }
    return obj;
  },
};

function createBasePipeStream(): PipeStream {
  return {
    streamId: "",
    document: undefined,
    currentPipelineName: "",
    targetStepName: "",
    currentHopNumber: 0,
    history: [],
    streamErrorData: undefined,
    contextParams: {},
    actionType: 0,
  };
}

export const PipeStream: MessageFns<PipeStream> = {
  encode(message: PipeStream, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.streamId !== "") {
      writer.uint32(10).string(message.streamId);
    }
    if (message.document !== undefined) {
      PipeDoc.encode(message.document, writer.uint32(18).fork()).join();
    }
    if (message.currentPipelineName !== "") {
      writer.uint32(26).string(message.currentPipelineName);
    }
    if (message.targetStepName !== "") {
      writer.uint32(34).string(message.targetStepName);
    }
    if (message.currentHopNumber !== 0) {
      writer.uint32(40).int64(message.currentHopNumber);
    }
    for (const v of message.history) {
      StepExecutionRecord.encode(v!, writer.uint32(50).fork()).join();
    }
    if (message.streamErrorData !== undefined) {
      ErrorData.encode(message.streamErrorData, writer.uint32(58).fork()).join();
    }
    Object.entries(message.contextParams).forEach(([key, value]) => {
      PipeStream_ContextParamsEntry.encode({ key: key as any, value }, writer.uint32(66).fork()).join();
    });
    if (message.actionType !== 0) {
      writer.uint32(72).int32(message.actionType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PipeStream {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipeStream();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.streamId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.document = PipeDoc.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.currentPipelineName = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.targetStepName = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.currentHopNumber = longToNumber(reader.int64());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.history.push(StepExecutionRecord.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.streamErrorData = ErrorData.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          const entry8 = PipeStream_ContextParamsEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.contextParams[entry8.key] = entry8.value;
          }
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.actionType = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PipeStream {
    return {
      streamId: isSet(object.streamId) ? globalThis.String(object.streamId) : "",
      document: isSet(object.document) ? PipeDoc.fromJSON(object.document) : undefined,
      currentPipelineName: isSet(object.currentPipelineName) ? globalThis.String(object.currentPipelineName) : "",
      targetStepName: isSet(object.targetStepName) ? globalThis.String(object.targetStepName) : "",
      currentHopNumber: isSet(object.currentHopNumber) ? globalThis.Number(object.currentHopNumber) : 0,
      history: globalThis.Array.isArray(object?.history)
        ? object.history.map((e: any) => StepExecutionRecord.fromJSON(e))
        : [],
      streamErrorData: isSet(object.streamErrorData) ? ErrorData.fromJSON(object.streamErrorData) : undefined,
      contextParams: isObject(object.contextParams)
        ? Object.entries(object.contextParams).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      actionType: isSet(object.actionType) ? actionTypeFromJSON(object.actionType) : 0,
    };
  },

  toJSON(message: PipeStream): unknown {
    const obj: any = {};
    if (message.streamId !== "") {
      obj.streamId = message.streamId;
    }
    if (message.document !== undefined) {
      obj.document = PipeDoc.toJSON(message.document);
    }
    if (message.currentPipelineName !== "") {
      obj.currentPipelineName = message.currentPipelineName;
    }
    if (message.targetStepName !== "") {
      obj.targetStepName = message.targetStepName;
    }
    if (message.currentHopNumber !== 0) {
      obj.currentHopNumber = Math.round(message.currentHopNumber);
    }
    if (message.history?.length) {
      obj.history = message.history.map((e) => StepExecutionRecord.toJSON(e));
    }
    if (message.streamErrorData !== undefined) {
      obj.streamErrorData = ErrorData.toJSON(message.streamErrorData);
    }
    if (message.contextParams) {
      const entries = Object.entries(message.contextParams);
      if (entries.length > 0) {
        obj.contextParams = {};
        entries.forEach(([k, v]) => {
          obj.contextParams[k] = v;
        });
      }
    }
    if (message.actionType !== 0) {
      obj.actionType = actionTypeToJSON(message.actionType);
    }
    return obj;
  },
};

function createBasePipeStream_ContextParamsEntry(): PipeStream_ContextParamsEntry {
  return { key: "", value: "" };
}

export const PipeStream_ContextParamsEntry: MessageFns<PipeStream_ContextParamsEntry> = {
  encode(message: PipeStream_ContextParamsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PipeStream_ContextParamsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipeStream_ContextParamsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PipeStream_ContextParamsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: PipeStream_ContextParamsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },
};

function bytesFromBase64(b64: string): Uint8Array {
  if ((globalThis as any).Buffer) {
    return Uint8Array.from(globalThis.Buffer.from(b64, "base64"));
  } else {
    const bin = globalThis.atob(b64);
    const arr = new Uint8Array(bin.length);
    for (let i = 0; i < bin.length; ++i) {
      arr[i] = bin.charCodeAt(i);
    }
    return arr;
  }
}

function base64FromBytes(arr: Uint8Array): string {
  if ((globalThis as any).Buffer) {
    return globalThis.Buffer.from(arr).toString("base64");
  } else {
    const bin: string[] = [];
    arr.forEach((byte) => {
      bin.push(globalThis.String.fromCharCode(byte));
    });
    return globalThis.btoa(bin.join(""));
  }
}

function toTimestamp(date: Date): Timestamp {
  const seconds = Math.trunc(date.getTime() / 1_000);
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function longToNumber(int64: { toString(): string }): number {
  const num = globalThis.Number(int64.toString());
  if (num > globalThis.Number.MAX_SAFE_INTEGER) {
    throw new globalThis.Error("Value is larger than Number.MAX_SAFE_INTEGER");
  }
  if (num < globalThis.Number.MIN_SAFE_INTEGER) {
    throw new globalThis.Error("Value is smaller than Number.MIN_SAFE_INTEGER");
  }
  return num;
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
}
